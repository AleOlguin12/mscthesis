---
title: "VAR vs NN"
author: "Andrés A. Saenz Guzmán"
date: "13/4/2020"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, results = 'hide')
```

## 1. Libraries

Lets start by loading the packages that we will be using

```{r libraries, echo=TRUE}
library(ggplot2)
library(tidyverse)
library(readxl)
library(tensorflow)
library(keras)
library(vars)
library(stargazer)
library(forecast)
```

## 2. Data

We present data for different countries:

# 2.1. Data for US

```{r load data US, echo=TRUE, results='hide'}
OutputGapUS <- read_excel("C:/Users/aasg/OneDrive/Escritorio/Tilburg University/Thesis/Data/US_output_gap_proxy_Industrial_Activity.xlsx")
OutputGapUS <- as.numeric(OutputGapUS$...5[71:371])

infUS <- read_excel("C:/Users/aasg/OneDrive/Escritorio/Tilburg University/Thesis/Data/US_Infl.xlsx")
infUS <- as.numeric(infUS$...3[71:371])

intrateUS <- read_excel("C:/Users/aasg/OneDrive/Escritorio/Tilburg University/Thesis/Data/US_interest_rate.xlsx")
intrateUS <- as.numeric(intrateUS$...2[65:365])/100

M2US <- read_excel("C:/Users/aasg/OneDrive/Escritorio/Tilburg University/Thesis/Data/US_M2.xlsx")
M2US <- as.numeric(M2US$...10[67:367])

urateUS <- read_excel("C:/Users/aasg/OneDrive/Escritorio/Tilburg University/Thesis/Data/US_u_rate.xls")
urateUS <- as.numeric(urateUS$...2[71:371])/100

RERUS <- read_excel("C:/Users/aasg/OneDrive/Escritorio/Tilburg University/Thesis/Data/US_RER.xlsx")
RERUS <- as.numeric(RERUS$...3[23:323])

nomWUS <- read_excel("C:/Users/aasg/OneDrive/Escritorio/Tilburg University/Thesis/Data/US_nom_wages.xlsx")
nomWUS <- as.numeric(nomWUS$...3[71:371])
realWUS <- nomWUS - infUS

nmonths = 301
mdate <- seq(as.Date("1995-1-1"), by = "month", length.out = nmonths)

dataUS <- data.frame(mdate, infUS, intrateUS, M2US, OutputGapUS, urateUS, RERUS, realWUS, row.names = NULL)
```

Notice that some of the data is divided by 100. This is to scale the data such that 1% is wrote as 0.01 instead of 1. Also, the data represents the year on year (YoY) growth. Finally, although the data for most variables was available from January 1990 or earlier dates, the current real exchange rate index methodology was available since January 1994, therefore, the series cover the period January 1995 - January 2020.

# 2.2. Data for EA

```{r load data EA, echo=TRUE, results='hide'}
infEA <- read_excel("C:/Users/aasg/OneDrive/Escritorio/Tilburg University/Thesis/Data/EA_Infl.xlsx")
infEA <- as.numeric(infEA$...3[29:281]) #283 = march 2020

intrateEA <- read_excel("C:/Users/aasg/OneDrive/Escritorio/Tilburg University/Thesis/Data/EA_interest_rate.xlsx") #Need to update the data
intrateEA <- as.numeric(intrateEA$...3[11:263]) #265 = march 2020

M2EA <- read_excel("C:/Users/aasg/OneDrive/Escritorio/Tilburg University/Thesis/Data/EA_M2.xlsx")
M2EA <- as.numeric(M2EA$...5[233:485]) #486 = February 2020

OutputGapEA <- read_excel("C:/Users/aasg/OneDrive/Escritorio/Tilburg University/Thesis/Data/EA_Ind_prod.xlsx")
OutputGapEA <- as.numeric(OutputGapEA$...5[101:353]) #353 = January 2020

urateEA <- read_excel("C:/Users/aasg/OneDrive/Escritorio/Tilburg University/Thesis/Data/EA_u_rate.xlsx")
urateEA <- as.numeric(urateEA$...3[14:266]) #267 = February 2020

REREA <- read_excel("C:/Users/aasg/OneDrive/Escritorio/Tilburg University/Thesis/Data/EA_RER.xlsx")
REREA <- as.numeric(REREA$...3[71:323]) #324 = February 2020

nmonthsEA <- 253
mdateEA <- seq(as.Date("1999-1-1"), by = "month", length.out = nmonthsEA)

dataEA <- data.frame(mdateEA, infEA, intrateEA, M2EA, OutputGapEA, urateEA, REREA, row.names = NULL)
```

In the case of the Euro Area, I have'nt been able to find free data on wages. Also, since the European Central Bank (ECB) was created in 1998, most of the data such as interest rates are available from January 1999.

# 2.3. Data for the NL

```{r load data NL, echo=TRUE, results='hide'}
infNL <- read_excel("C:/Users/aasg/OneDrive/Escritorio/Tilburg University/Thesis/Data/NL_Infl.xlsx")
infNL <- as.numeric(infNL$...2[29:281])/100

intrateNL <- intrateEA 

M2NL <- M2EA 

OutputGapNL <- read_excel("C:/Users/aasg/OneDrive/Escritorio/Tilburg University/Thesis/Data/NL_Ind_prod.xlsx") #Need to update the data
OutputGapNL <- as.numeric(OutputGapNL$...5[119:371])

urateNL <- read_excel("C:/Users/aasg/OneDrive/Escritorio/Tilburg University/Thesis/Data/NL_u_rate.xlsx")
urateNL <- as.numeric(urateNL$...3[197:449]) 

RERNL <- REREA

nomWNL <- read_excel("C:/Users/aasg/OneDrive/Escritorio/Tilburg University/Thesis/Data/NL_wages_index.xlsx")
nomWNL <- as.numeric(nomWNL$...3[119:371])
realWNL <- nomWNL - infNL

nmonthsNL <- 253
mdateNL <- seq(as.Date("1999-1-1"), by = "month", length.out = nmonthsNL)

dataNL <- data.frame(mdateNL, infNL, intrateNL, M2NL, OutputGapNL, urateNL, RERNL, realWNL, row.names = NULL)
```

For the NL I will recycle the data of some EA variables (Interest Rate, M2, RER). The reason behind this is interest rate and money supply M2 are monetary policy instruments that are common across all members of the EA. Likewise, the exchange rate is fixed since the introduction of the Euro.

# 2.4. Data for CL 

```{r data for CL, echo=TRUE, results='hide'}
OutputGapCL <- read_excel("C:/Users/aasg/OneDrive/Escritorio/Tilburg University/Thesis/Data/CL_Ind_prod.xlsx")
OutputGapCL <- as.numeric(OutputGapCL$HP_CYCLE[37:326])

infCL <- read_excel("C:/Users/aasg/OneDrive/Escritorio/Tilburg University/Thesis/Data/CL_Infl.xlsx")
infCL <- as.numeric(infCL$`Inflation`[13:302])

intrateCL <- read_excel("C:/Users/aasg/OneDrive/Escritorio/Tilburg University/Thesis/Data/CL_interest_rate.xlsx")
intrateCL <- as.numeric(intrateCL$...3[11:300])

M2CL <- read_excel("C:/Users/aasg/OneDrive/Escritorio/Tilburg University/Thesis/Data/CL_M2.xlsx")
M2CL <- as.numeric(M2CL$...5[27:316])

urateCL <- read_excel("C:/Users/aasg/OneDrive/Escritorio/Tilburg University/Thesis/Data/CL_u_rate.xlsx")
urateCL <- as.numeric(urateCL$`x/100`[25:314])

RERCL <- read_excel("C:/Users/aasg/OneDrive/Escritorio/Tilburg University/Thesis/Data/CL_E_RER.xlsx")
RERCL <- as.numeric(RERCL$...4[27:316])

realWCL <- read_excel("C:/Users/aasg/OneDrive/Escritorio/Tilburg University/Thesis/Data/CL_real_W.xlsx")
realWCL <- as.numeric(realWCL$`RW09=100`[37:326])


nmonthsCL = 290
mdateCL <- seq(as.Date("1996-1-1"), by = "month", length.out = nmonthsCL)

dataCL <- data.frame(mdateCL, infCL, intrateCL, M2CL, OutputGapCL, urateCL, RERCL, realWCL, row.names = NULL)
```

# 3.5. Data for MX

```{r data for MX, echo=TRUE, results='hide'}
OutputGapMX <- read_excel("C:/Users/aasg/OneDrive/Escritorio/Tilburg University/Thesis/Data/MX_output_gap_proxy_Industrial_Activity.xlsx")
OutputGapMX <- as.numeric(OutputGapMX$`HP Cycle`[97:325])

infMX <- read_excel("C:/Users/aasg/OneDrive/Escritorio/Tilburg University/Thesis/Data/MX_inf.xlsx")
infMX <- as.numeric(infMX$...3[393:621]) 

intrateMX <- read_excel("C:/Users/aasg/OneDrive/Escritorio/Tilburg University/Thesis/Data/MX_interest_rate.xlsx")
intrateMX <- as.numeric(intrateMX$...3[174:402])/100 #TIIE 28

M2MX <- read_excel("C:/Users/aasg/OneDrive/Escritorio/Tilburg University/Thesis/Data/MX_M2.xlsx")
M2MX <- as.numeric(M2MX$...15[19:247])

urateMX <- read_excel("C:/Users/aasg/OneDrive/Escritorio/Tilburg University/Thesis/Data/MX_u_rate.xlsx")
urateMX <- as.numeric(urateMX$`x/100`[49:277])

RERMX <- read_excel("C:/Users/aasg/OneDrive/Escritorio/Tilburg University/Thesis/Data/MX_RER.xlsx")
RERMX <- as.numeric(RERMX$...3[150:378])

realWMX <- read_excel("C:/Users/aasg/OneDrive/Escritorio/Tilburg University/Thesis/Data/MX_r_wages.xlsx")
realWMX <- as.numeric(realWMX$...5[86:314])


nmonthsMX = 229
mdateMX <- seq(as.Date("2001-1-1"), by = "month", length.out = nmonthsMX)

dataMX <- data.frame(mdateMX, infMX, intrateMX, M2MX, OutputGapMX, urateMX, RERMX, realWMX, row.names = NULL) 
```

# 3. Visualizing the data

# 3.1. Data for the US

```{r Plots data US, echo=FALSE}
pus1colours <- c("Inflation" = "darkred", "Interest Rate" = "steelblue")
pus1 <- ggplot(data = dataUS, aes(x = mdate)) + 
  geom_line(aes(y = infUS, color = "Inflation")) +
  geom_line(aes(y = intrateUS, color = "Interest Rate")) +
  labs(x = "", y = "", color = "Legend", title = "Inflation and Interest Rate (US)") +
  scale_color_manual(values = pus1colours)
 
pus2colours <- c("Inflation" = "darkred", "M2" = "steelblue")
pus2 <- ggplot(data = dataUS, aes(x = mdate)) + 
  geom_line(aes(y = infUS, color = "Inflation")) +
  geom_line(aes(y = M2US, color = "M2")) +
  labs(x = "", y = "", color = "Legend", title = "Inflation and M2 Money Supply (US)") +
  scale_color_manual(values = pus2colours)

pus3colours <- c("Inflation" = "darkred", "Output Gap" = "steelblue")
pus3 <- ggplot(data = dataUS, aes(x = mdate)) + 
  geom_line(aes(y = infUS, color = "Inflation")) +
  geom_line(aes(y = OutputGapUS, color = "Output Gap")) +
  labs(x = "", y = "", color = "Legend", title = "Inflation and Output Gap (US)") +
  scale_color_manual(values = pus3colours)

pus4colours <- c("Inflation" = "darkred", "Unemployment Rate" = "steelblue")
pus4 <- ggplot(data = dataUS, aes(x = mdate)) + 
  geom_line(aes(y = infUS, color = "Inflation")) +
  geom_line(aes(y = urateUS, color = "Unemployment Rate")) +
  labs(x = "", y = "", color = "Legend", title = "Inflation and Unemployment Rate (US)") +
  scale_color_manual(values = pus4colours)

pus5colours <- c("Inflation" = "darkred", "Real Exchange Rate" = "steelblue")
pus5 <- ggplot(data = dataUS, aes(x = mdate)) + 
  geom_line(aes(y = infUS, color = "Inflation")) +
  geom_line(aes(y = RERUS, color = "Real Exchange Rate")) +
  labs(x = "", y = "", color = "Legend", title = "Inflation and Real Exchange Rate (US)") +
  scale_color_manual(values = pus5colours)

pus6colours <- c("Inflation" = "darkred", "Real Wages" = "steelblue")
pus6 <- ggplot(data = dataUS, aes(x = mdate)) + 
  geom_line(aes(y = infUS, color = "Inflation")) +
  geom_line(aes(y = realWUS, color = "Real Wages")) +
  labs(x = "", y = "", color = "Legend", title = "Inflation and Real Wages (US)") +
  scale_color_manual(values = pus6colours)

pus1
pus2
pus3
pus4
pus5
pus6
```

# 3.2. Data for the EA

```{r Plots data EA, echo=FALSE}
pea1colours <- c("Inflation" = "darkred", "Interest Rate" = "steelblue")
pea1 <- ggplot(data = dataEA, aes(x = mdateEA)) + 
  geom_line(aes(y = infEA, color = "Inflation")) +
  geom_line(aes(y = intrateEA, color = "Interest Rate")) +
  labs(x = "", y = "", color = "Legend", title = "Inflation and Interest Rate (EA)") +
  scale_color_manual(values = pea1colours)
 
pea2colours <- c("Inflation" = "darkred", "M2" = "steelblue")
pea2 <- ggplot(data = dataEA, aes(x = mdateEA)) + 
  geom_line(aes(y = infEA, color = "Inflation")) +
  geom_line(aes(y = M2EA, color = "M2")) +
  labs(x = "", y = "", color = "Legend", title = "Inflation and M2 Money Supply (EA)") +
  scale_color_manual(values = pea2colours)

pea3colours <- c("Inflation" = "darkred", "Output Gap" = "steelblue")
pea3 <- ggplot(data = dataEA, aes(x = mdateEA)) + 
  geom_line(aes(y = infEA, color = "Inflation")) +
  geom_line(aes(y = OutputGapEA, color = "Output Gap")) +
  labs(x = "", y = "", color = "Legend", title = "Inflation and Output Gap (EA)") +
  scale_color_manual(values = pea3colours)

pea4colours <- c("Inflation" = "darkred", "Unemployment Rate" = "steelblue")
pea4 <- ggplot(data = dataEA, aes(x = mdateEA)) + 
  geom_line(aes(y = infEA, color = "Inflation")) +
  geom_line(aes(y = urateEA, color = "Unemployment Rate")) +
  labs(x = "", y = "", color = "Legend", title = "Inflation and Unemployment Rate (EA)") +
  scale_color_manual(values = pea4colours)

pea5colours <- c("Inflation" = "darkred", "Real Exchange Rate" = "steelblue")
pea5 <- ggplot(data = dataEA, aes(x = mdateEA)) + 
  geom_line(aes(y = infEA, color = "Inflation")) +
  geom_line(aes(y = REREA, color = "Real Exchange Rate")) +
  labs(x = "", y = "", color = "Legend", title = "Inflation and Real Exchange Rate (EA)") +
  scale_color_manual(values = pea5colours)

pea1
pea2
pea3
pea4
pea5

```

# 3.3. Data for the NL

```{r data for the NL, echo=FALSE}
pnl1colours <- c("Inflation" = "darkred", "Interest Rate" = "steelblue")
pnl1 <- ggplot(data = dataNL, aes(x = mdateNL)) + 
  geom_line(aes(y = infNL, color = "Inflation")) +
  geom_line(aes(y = intrateNL, color = "Interest Rate")) +
  labs(x = "", y = "", color = "Legend", title = "Inflation and Interest Rate (NL)") +
  scale_color_manual(values = pnl1colours)
 
pnl2colours <- c("Inflation" = "darkred", "M2" = "steelblue")
pnl2 <- ggplot(data = dataNL, aes(x = mdateNL)) + 
  geom_line(aes(y = infNL, color = "Inflation")) +
  geom_line(aes(y = M2NL, color = "M2")) +
  labs(x = "", y = "", color = "Legend", title = "Inflation and M2 Money Supply (NL)") +
  scale_color_manual(values = pnl2colours)

pnl3colours <- c("Inflation" = "darkred", "Output Gap" = "steelblue")
pnl3 <- ggplot(data = dataNL, aes(x = mdateNL)) + 
  geom_line(aes(y = infNL, color = "Inflation")) +
  geom_line(aes(y = OutputGapNL, color = "Output Gap")) +
  labs(x = "", y = "", color = "Legend", title = "Inflation and Output Gap (NL)") +
  scale_color_manual(values = pnl3colours)

pnl4colours <- c("Inflation" = "darkred", "Unemployment Rate" = "steelblue")
pnl4 <- ggplot(data = dataNL, aes(x = mdateNL)) + 
  geom_line(aes(y = infNL, color = "Inflation")) +
  geom_line(aes(y = urateNL, color = "Unemployment Rate")) +
  labs(x = "", y = "", color = "Legend", title = "Inflation and Unemployment Rate (NL)") +
  scale_color_manual(values = pnl4colours)

pnl5colours <- c("Inflation" = "darkred", "Real Exchange Rate" = "steelblue")
pnl5 <- ggplot(data = dataNL, aes(x = mdateNL)) + 
  geom_line(aes(y = infNL, color = "Inflation")) +
  geom_line(aes(y = RERNL, color = "Real Exchange Rate")) +
  labs(x = "", y = "", color = "Legend", title = "Inflation and Real Exchange Rate (NL)") +
  scale_color_manual(values = pnl5colours)

pnl6colours <- c("Inflation" = "darkred", "Real Wages" = "steelblue")
pnl6 <- ggplot(data = dataNL, aes(x = mdateNL)) + 
  geom_line(aes(y = infNL, color = "Inflation")) +
  geom_line(aes(y = realWNL, color = "Real Wages")) +
  labs(x = "", y = "", color = "Legend", title = "Inflation and Real Wages (NL)") +
  scale_color_manual(values = pnl6colours)

pnl1
pnl2
pnl3
pnl4
pnl5
pnl6
```

# 3.4 Data for CL

```{r data for the CL, echo=FALSE}
pcl1colours <- c("Inflation" = "darkred", "Interest Rate" = "steelblue")
pcl1 <- ggplot(data = dataCL, aes(x = mdateCL)) + 
  geom_line(aes(y = infCL, color = "Inflation")) +
  geom_line(aes(y = intrateCL, color = "Interest Rate")) +
  labs(x = "", y = "", color = "Legend", title = "Inflation and Interest Rate (CL)") +
  scale_color_manual(values = pcl1colours)
 
pcl2colours <- c("Inflation" = "darkred", "M2" = "steelblue")
pcl2 <- ggplot(data = dataCL, aes(x = mdateCL)) + 
  geom_line(aes(y = infCL, color = "Inflation")) +
  geom_line(aes(y = M2CL, color = "M2")) +
  labs(x = "", y = "", color = "Legend", title = "Inflation and M2 Money Supply (CL)") +
  scale_color_manual(values = pcl2colours)

pcl3colours <- c("Inflation" = "darkred", "Output Gap" = "steelblue")
pcl3 <- ggplot(data = dataCL, aes(x = mdateCL)) + 
  geom_line(aes(y = infCL, color = "Inflation")) +
  geom_line(aes(y = OutputGapCL, color = "Output Gap")) +
  labs(x = "", y = "", color = "Legend", title = "Inflation and Output Gap (CL)") +
  scale_color_manual(values = pcl3colours)

pcl4colours <- c("Inflation" = "darkred", "Unemployment Rate" = "steelblue")
pcl4 <- ggplot(data = dataCL, aes(x = mdateCL)) + 
  geom_line(aes(y = infCL, color = "Inflation")) +
  geom_line(aes(y = urateCL, color = "Unemployment Rate")) +
  labs(x = "", y = "", color = "Legend", title = "Inflation and Unemployment Rate (CL)") +
  scale_color_manual(values = pcl4colours)

pcl5colours <- c("Inflation" = "darkred", "Real Exchange Rate" = "steelblue")
pcl5 <- ggplot(data = dataCL, aes(x = mdateCL)) + 
  geom_line(aes(y = infCL, color = "Inflation")) +
  geom_line(aes(y = RERCL, color = "Real Exchange Rate")) +
  labs(x = "", y = "", color = "Legend", title = "Inflation and Real Exchange Rate (CL)") +
  scale_color_manual(values = pcl5colours)

pcl6colours <- c("Inflation" = "darkred", "Real Wages" = "steelblue")
pcl6 <- ggplot(data = dataCL, aes(x = mdateCL)) + 
  geom_line(aes(y = infCL, color = "Inflation")) +
  geom_line(aes(y = realWCL, color = "Real Wages")) +
  labs(x = "", y = "", color = "Legend", title = "Inflation and Real Wages (CL)") +
  scale_color_manual(values = pcl6colours)

pcl1
pcl2
pcl3
pcl4
pcl5
pcl6
```

# 3.5. Data for MX

```{r data for the MX, echo=FALSE}
pmx1colours <- c("Inflation" = "darkred", "Interest Rate" = "steelblue")
pmx1 <- ggplot(data = dataMX, aes(x = mdateMX)) + 
  geom_line(aes(y = infMX, color = "Inflation")) +
  geom_line(aes(y = intrateMX, color = "Interest Rate")) +
    labs(x = "", y = "", color = "Legend", title = "Inflation and Interest Rate (MX)") +
  scale_color_manual(values = pmx1colours)
 
pmx2colours <- c("Inflation" = "darkred", "M2" = "steelblue")
pmx2 <- ggplot(data = dataMX, aes(x = mdateMX)) + 
  geom_line(aes(y = infMX, color = "Inflation")) +
  geom_line(aes(y = M2MX, color = "M2")) +
  labs(x = "", y = "", color = "Legend", title = "Inflation and M2 Money Supply (MX)") +
  scale_color_manual(values = pmx2colours)

pmx3colours <- c("Inflation" = "darkred", "Output Gap" = "steelblue")
pmx3 <- ggplot(data = dataMX, aes(x = mdateMX)) + 
  geom_line(aes(y = infMX, color = "Inflation")) +
  geom_line(aes(y = OutputGapMX, color = "Output Gap")) +
  labs(x = "", y = "", color = "Legend", title = "Inflation and Output Gap (MX)") +
  scale_color_manual(values = pmx3colours)

pmx4colours <- c("Inflation" = "darkred", "Unemployment Rate" = "steelblue")
pmx4 <- ggplot(data = dataMX, aes(x = mdateMX)) + 
  geom_line(aes(y = infMX, color = "Inflation")) +
  geom_line(aes(y = urateMX, color = "Unemployment Rate")) +
  labs(x = "", y = "", color = "Legend", title = "Inflation and Unemployment Rate (MX)") +
  scale_color_manual(values = pmx4colours)

pmx5colours <- c("Inflation" = "darkred", "Real Exchange Rate" = "steelblue")
pmx5 <- ggplot(data = dataMX, aes(x = mdateMX)) + 
  geom_line(aes(y = infMX, color = "Inflation")) +
  geom_line(aes(y = RERMX, color = "Real Exchange Rate")) +
  labs(x = "", y = "", color = "Legend", title = "Inflation and Real Exchange Rate (MX)") +
  scale_color_manual(values = pmx5colours)

pmx6colours <- c("Inflation" = "darkred", "Real Wages" = "steelblue")
pmx6 <- ggplot(data = dataMX, aes(x = mdateMX)) + 
  geom_line(aes(y = infMX, color = "Inflation")) +
  geom_line(aes(y = realWMX, color = "Real Wages")) +
  labs(x = "", y = "", color = "Legend", title = "Inflation and Real Wages (MX)") +
  scale_color_manual(values = pmx6colours)

pmx1
pmx2
pmx3
pmx4
pmx5
pmx6
```

## 4. A benchmark model

In the following sections we are going to compare the performance of a VAR model and a NN when tasked with inflation forecasting. However, our first step is to build a benchmark model to set a baseline. For the benchmark, I will build an autoregressive order 1 model. Although this model may be naive, it is common to find this specification when dealing with inflation prediction. Therefore, the benchmark model will take the following form:

                    $\pi_{t+1} = \alpha + \beta \pi_t + epsilon_{t+1}$
                    
```{r AR1 US}
marus <- Arima(dataUS$infUS[1:289], order = c(1,0,0))
marus

checkresiduals(marus)

marusfcast <- forecast(marus, h = 12)
autoplot(marusfcast)

marusferror <- marusfcast$mean - dataUS$infUS[290:301]
autoplot(marusferror)
```

```{r AR1 EA}
marea <- Arima(dataEA$infEA[1:241], order = c(1,0,0))
marus

checkresiduals(marea)

mareafcast <- forecast(marea, h = 12)
autoplot(mareafcast)

mareaferror <- mareafcast$mean - dataEA$infEA[242:253]
autoplot(mareaferror)
```

```{r AR1 NL}
marnl <- Arima(dataNL$infNL[1:241], order = c(1,0,0))
marus

checkresiduals(marnl)

marnlfcast <- forecast(marnl, h = 12)
autoplot(marnlfcast)

marnlferror <- marnlfcast$mean - dataNL$infNL[242:253]
autoplot(marnlferror)
```

```{r AR1 CL}
marcl <- Arima(dataCL$infCL[1:278], order = c(1,0,0))
marcl

checkresiduals(marcl)

marclfcast <- forecast(marcl, h = 12)
autoplot(marclfcast)

marclferror <- marclfcast$mean - dataCL$infCL[279:290]
autoplot(marclferror)
```

```{r AR1 MX}
marmx <- Arima(dataMX$infMX[1:217], order = c(1,0,0))
marmx

checkresiduals(marmx)

marmxfcast <- forecast(marmx, h = 12)
autoplot(marmxfcast)

marmxferror <- marmxfcast$mean - dataMX$infMX[218:229]
autoplot(marmxferror)
```

## 5. Vector Autoregressive Model

With the benchmark computed, now I will estimate a VAR model and forecast inflation a year into the future. The model takes into account monetary policy tools (interest rate and money supply M2) and controls for the output gap, unemployment rate, real wages and real exchange rate.

# 5.1. VAR for the US

```{r VAR US}
mvaruslength <- VARselect(dataUS[,2:8], type = "const", lag.max = 12)[["selection"]]
mvaruslength
```

The function VARselect indicates the number of lags that should be used in the model. I will use the AIC(n) criteria. In this case, I'll use 3 lags to build the VAR model for the US.

```{r VAR US}
mvarus <- VAR(dataUS[1:289, 2:8], p = 3)
mvarus

checkresiduals(mvarus$varresult$infUS)

acf(resid(mvarus))

mvarusfcast <- forecast(mvarus$datamat$infUS , h = 12)
autoplot(mvarusfcast)

mvarusferror <- mvarusfcast$mean - dataUS$infUS[290:301]
autoplot(mvarusferror)
```

An interesting question is how does the forecast errors of the VAR model compare to the benchmark. For that we take the difference of the errors of both models and represent them in an histogram. If the difference is centered on cero, then there is virtualy no difference between the models. However, the distribution is biased to the negative values, then the VAR model produces better predictions. Analogously, if the results are biased toward positive values, then the benchmark is better.

```{r VAR vs AR1 US}

varvsarus <- abs(mvarusferror) - abs(marusferror)
varvsarus

ggplot(as.data.frame(varvsarus), aes(varvsarus)) + geom_histogram()
```

Although the difference is leaning toward positive values, the difference of the errors in both models is almost zero.

# 5.2. VAR for the EA

```{r VAR EA}
mvarealength <- VARselect(dataEA[,2:7], type = "const", lag.max = 12)[["selection"]]
mvarealength
```

Again, the AIC(n) criteria recomends the use of 3 lags.

```{r VAR EA}
mvarea <- VAR(dataEA[1:241, 2:7], p = 3)
mvarea

checkresiduals(mvarea$varresult$infEA)

acf(resid(mvarea))

mvareafcast <- forecast(mvarea$datamat$infEA , h = 12)
autoplot(mvareafcast)

mvareaferror <- mvareafcast$mean - dataEA$infEA[242:253]
autoplot(mvareaferror)
```

Now I check whick model offers a better prediction.

```{r VAR vs AR1 EA}

varvsarea <- abs(mvareaferror) - abs(mareaferror)
varvsarea

ggplot(as.data.frame(varvsarea), aes(varvsarea)) + geom_histogram()
```

Again, the benchmark model seems to be slightly better than the VAR.

# 5.3. VAR for the NL

```{r VAR NL}
mvarnllength <- VARselect(dataNL[,2:7], type = "const", lag.max = 12)[["selection"]]
mvarnllength
```

Once again, the AIC(n) criteria recomends the use of 3 lags.

```{r VAR NL}
mvarnl <- VAR(dataNL[1:241, 2:7], p = 3)
mvarnl

checkresiduals(mvarnl$varresult$infNL)

acf(resid(mvarnl))

mvarnlfcast <- forecast(mvarnl$datamat$infNL , h = 12)
autoplot(mvarnlfcast)

mvarnlferror <- mvarnlfcast$mean - dataNL$infNL[242:253]
autoplot(mvarnlferror)
```

Now I check whick model offers a better prediction.

```{r VAR vs AR1 NL}

varvsarnl <- abs(mvarnlferror) - abs(marnlferror)
varvsarnl

ggplot(as.data.frame(varvsarnl), aes(varvsarnl)) + geom_histogram()
```

Again, the forecast errors are slightly centeres in the negative values, implying a higher predective power for the AR(1) relative to an VAR.

# 5.4. VAR for CL

```{r VAR CL}
mvarcllength <- VARselect(dataCL[,2:8], type = "const", lag.max = 12)[["selection"]]
mvarcllength
```

This time the AIC(n) criteria recomends the use of 4 lags.

```{r VAR CL}
mvarcl <- VAR(dataCL[1:278, 2:8], p = 4)
mvarcl

checkresiduals(mvarcl$varresult$infCL)

acf(resid(mvarcl))

mvarclfcast <- forecast(mvarcl$datamat$infCL , h = 12)
autoplot(mvarclfcast)

mvarclferror <- mvarclfcast$mean - dataCL$infCL[279:290]
autoplot(mvarclferror)
```

Now I verify wheter the VAR or the benchmark produce better output when forecasting inflation.

```{r VAR vs AR1 CL}

varvsarcl <- abs(mvarclferror) - abs(marclferror)
varvsarcl

ggplot(as.data.frame(varvsarcl), aes(varvsarcl)) + geom_histogram()
```

Once again, the benchmark model produces better output than the VAR. Although, the difference is close to zero.

# 5.5. VAR for MX

```{r VAR MX}
mvarmxlength <- VARselect(dataMX[,2:8], type = "const", lag.max = 12)[["selection"]]
mvarmxlength
```

This time the AIC(n) criteria recomends the use of 12 lags,i.e., the whole year. However, this produces an error that prevents us to compare the errors of the model relative to the benchmark. For this reason, I will use 10 lags instead (11 lags also generate inconsistent results later on).

```{r VAR MX}
mvarmx <- VAR(dataMX[1:217, 2:8], p = 10)
mvarmx

checkresiduals(mvarmx$varresult$infMX)

acf(resid(mvarmx))

mvarmxfcast <- forecast(mvarmx$datamat$infMX , h = 12)
autoplot(mvarmxfcast)

mvarmxferror <- mvarmxfcast$mean - dataMX$infMX[218:229]
autoplot(mvarmxferror)
```

Finally, we check which model produces less errors when tasked with prediction.

```{r VAR vs AR1 MX}

varvsarmx <- abs(mvarmxferror) - abs(marmxferror)
varvsarmx

ggplot(as.data.frame(varvsarmx), aes(varvsarmx)) + geom_histogram()
```


 In the mexican case, the VAR prediction is worse than the benchmark's forecast.
 
# 6. Neural Networks

The final part consists on training a neural network (NN) for inflation prediction. The NN will use the same variables as the VAR model and the hyperbolic tangent activation function, limiting the output to range between -1 and 1. The code of this section is based on https://blogs.rstudio.com/tensorflow/posts/2017-12-20-time-series-forecasting-with-recurrent-neural-networks/.

# 6.1. Preparing the Data

The idea is to use 12 months in the past to forecast up to 12 months into the future (lookback = delay = 12). Every month is a step, thus we set steps to 1 (steps = 1).

Usually, I would have to normalize the data. However, this was already done in section 2. Since all data is ina similar scale.


```{r divide data US}
data_nn_us <- as.matrix(dataUS[ , -1])
```

We create general function to preprocess the data

```{r generator function}
generator <- function(data, lookback, delay, min_index, max_index,
                      shuffle = FALSE, batch_size = 128, step = 6) {
  if (is.null(max_index))
    max_index <- nrow(data) - delay - 1
  i <- min_index + lookback
  function() {
    if (shuffle) {
      rows <- sample(c((min_index+lookback):max_index), size = batch_size)
    } else {
      if (i + batch_size >= max_index)
        i <<- min_index + lookback
      rows <- c(i:min(i+batch_size-1, max_index))
      i <<- i + length(rows)
    }

    samples <- array(0, dim = c(length(rows),
                                lookback / step,
                                dim(data)[[-1]]))
    targets <- array(0, dim = c(length(rows)))
                      
    for (j in 1:length(rows)) {
      indices <- seq(rows[[j]] - lookback, rows[[j]]-1,
                     length.out = dim(samples)[[2]])
      samples[j,,] <- data[indices,]
      targets[[j]] <- data[rows[[j]] + delay,2]
    }           
    list(samples, targets)
  }
}
```

Where data is the original normalized dataset, lookback is how many periods back the input data should go, delay is the forecasting target, min_index and max_index delimit the length of the array to draw data from, shuffle indicates whether to shuffle samples or draw them in a choronological order, batch_size is the number of observations per batch and step is the period at which you sample your data.

To apply the data we specify the parameters of the generator function:

```{r generator function parameters US}
lookback <- 12
step <- 1
delay <- 12
batch_size <- 50

train_data_us <- generator(
  data_nn_us, 
  lookback = lookback,
  delay = delay,
  min_index = 1,
  max_index = 228,
  shuffle = FALSE,
  step = step,
  batch_size = batch_size
)

val_data_us <- generator(
  data_nn_us, 
  lookback = lookback,
  delay = delay,
  min_index = 229,
  max_index = 289,
  step = step,
  batch_size = batch_size
)

test_data_us <- generator(
  data_nn_us, 
  lookback = lookback,
  delay = delay,
  min_index = 290,
  max_index = NULL,
  step = step,
  batch_size = batch_size
)

#Ammount of steps to draw from val.
val_steps <- (289 - 229 - lookback) / batch_size

#Ammount of steps to draw from test
test_steps <- (nrow(data_nn_us) - 289 - lookback) / batch_size
```

# 6.2. A NN Model

Now that we have preprocessed the data, we can build the NN.

```{r NN US}

nn_m_us <- keras_model_sequential() %>% 
  layer_flatten(input_shape = c(lookback / step, dim(data_nn_us)[-1])) %>% 
  layer_dense(units = 12, activation = "tanh") %>% 
  layer_dense(units = 1)

nn_m_us %>%  compile(
  optimizer = optimizer_rmsprop(),
  loss = "mae"
)

history_nn_us <- nn_m_us %>% fit_generator(
  train_data_us,
  steps_per_epoch = 100,
  epochs = 20,
  validation_data = val_data_us,
  validation_steps = 1
)

plot(history_nn_us)
```

As seen above, the NN is failing to fit the validation set while overfitting the training set. Therefore, this problem must be addressed before advancing in this section. To do so, I will use recurrent dropout.

```{r NN US}

nn_m_us <- keras_model_sequential() %>% 
  layer_gru(units = 12, activation = "tanh", dropout = 0.2, recurrent_dropout = 0.2,
            input_shape = list(NULL, dim(data_nn_us)[[-1]])) %>% 
  layer_dense(units = 1)

nn_m_us %>%  compile(
  optimizer = optimizer_rmsprop(),
  loss = "mae"
)

history_nn_us <- nn_m_us %>% fit_generator(
  train_data_us,
  steps_per_epoch = 100,
  epochs = 40,
  validation_data = val_data_us,
  validation_steps = 1
)

plot(history_nn_us)
```

Hmm... not sure if this output is good enough, Maybe a bidirectional RNN as sugested in the article?

Anyway, lets continue with forecasting

```{r NN forecast US}
save_model_hdf5(nn_m_us, 'my_model.h5')
nn_us <- load_model_hdf5('my_model.h5')
#dim(data_nn_us) <- c(dim(data_nn_us),1)
#nn_fcast_us <- predict(nn_us, data_nn_us , n.ahead = 12)
```

There seems to be issues with forecasting using the keras package. For this reason I will be using the nntar(function) of the forecast package.

# 6.1. NN for inflation in the US

```{r nnetar from forecast US}
library(forecast)

nn_m_us_2 <- nnetar(y = data_nn_us[1:289,1], 
                    p = 12, 
                    size = 6,
                    repeats = 400,
                    xreg = data_nn_us[1:289,2:7]
                    )

nn_fcast_us <- forecast(nn_m_us_2, 
                  h = 12, 
                  PI = TRUE, 
                  level = c(80,95), 
                  fan = TRUE,
                  xreg = data_nn_us[278:289,2:7],
                  npaths = 40
                  )
         
autoplot(nn_fcast_us, ylab = "Inflation")    

nn_ferror_us <- nn_fcast_us$mean - dataUS$infUS[290:301]
autoplot(nn_ferror_us)
```

Lets compare the performance of the NN to the benchmark and the VAR model.

```{r nnetar comparison US}
nn_vs_ar_us <- abs(nn_ferror_us) - abs(marusferror)
nn_vs_ar_us

nn_vs_var_us <- abs(nn_ferror_us) - abs(mvarusferror)
nn_vs_var_us

ggplot(as.data.frame(nn_vs_ar_us), aes(nn_vs_ar_us)) + geom_histogram()

ggplot(as.data.frame(nn_vs_var_us), aes(nn_vs_var_us)) + geom_histogram()
```

Seems that the NN performs the worst out of the three models when tasked with inflation performance in the US.

6.2. NN for inflation in the EA


```{r nnetar from forecast EA}

data_nn_ea <- as.matrix(dataEA[ , -1])

nn_m_ea <- nnetar(y = data_nn_ea[1:241,1], 
                    p = 12, 
                    size = 6,
                    repeats = 400,
                    xreg = data_nn_ea[1:241,2:6]
                    )

nn_fcast_ea <- forecast(nn_m_ea, 
                  h = 12, 
                  PI = TRUE, 
                  level = c(80,95), 
                  fan = TRUE,
                  xreg = data_nn_ea[230:241,2:6],
                  npaths = 40
                  )
         
autoplot(nn_fcast_ea, ylab = "Inflation")    

nn_ferror_ea <- nn_fcast_ea$mean - dataEA$infEA[242:253]
autoplot(nn_ferror_ea)
```

Now I compare the performance of the models.

```{r nnetar comparison EA}
nn_vs_ar_ea <- abs(nn_ferror_ea) - abs(mareaferror)
nn_vs_ar_ea

nn_vs_var_ea <- abs(nn_ferror_ea) - abs(mvareaferror)
nn_vs_var_ea

ggplot(as.data.frame(nn_vs_ar_ea), aes(nn_vs_ar_ea)) + geom_histogram()

ggplot(as.data.frame(nn_vs_var_ea), aes(nn_vs_var_ea)) + geom_histogram()
```

In the case of the Euro Area, the NN seems to perform better than the VAR and the AR(1) process. This is because in both cases, the absolute difference of the errors are leaning toward negative values. This is displayed in the histograms above.

# 6.3. NN for inflation in the NL

```{r nnetar from forecast NL}

data_nn_nl <- as.matrix(dataNL[ , -1])

nn_m_nl <- nnetar(y = data_nn_nl[1:241,1], 
                    p = 12, 
                    size = 6,
                    repeats = 400,
                    xreg = data_nn_nl[1:241,2:6]
                    )

nn_fcast_nl <- forecast(nn_m_nl,
                  h = 12, 
                  PI = TRUE, 
                  level = c(80,95), 
                  fan = TRUE,
                  xreg = data_nn_nl[230:241,2:6],
                  npaths = 40
                  )
         
autoplot(nn_fcast_nl, ylab = "Inflation")    

nn_ferror_nl <- nn_fcast_nl$mean - dataNL$infNL[242:253]
autoplot(nn_ferror_nl)
```

As usual, now I compare the forecast errors across models.

```{r nnetar comparison NL}
nn_vs_ar_nl <- abs(nn_ferror_nl) - abs(marnlferror)
nn_vs_ar_nl

nn_vs_var_nl <- abs(nn_ferror_nl) - abs(mvarnlferror)
nn_vs_var_nl

ggplot(as.data.frame(nn_vs_ar_nl), aes(nn_vs_ar_nl)) + geom_histogram()

ggplot(as.data.frame(nn_vs_var_nl), aes(nn_vs_var_nl)) + geom_histogram()
```

Is hard to tell by looking at the hitograms, if the NN performs better than the VAR and the benchmark when predicting futute inflation in the Netherlands. Therefore, I will procede to calculate the mean.

```{r}
mean_nn_ar_nl <- mean(nn_vs_ar_nl)
mean_nn_var_nl <- mean(nn_vs_var_nl)

mean_nn_ar_nl
mean_nn_var_nl


```

Since the mean of the difference in forecasting errors of the NN compared to the AR(1) is 0.0002, it seems that the benchmark performs better, while the respective value for the NN compared to the VAR (-0.0018) would indicate that the NN outperforms the predictions of the VAR. Although, both these values are close to zero.

# 6.4. NN for inflation in CL

```{r nnetar from forecast CL}

data_nn_cl <- as.matrix(dataCL[ , -1])

nn_m_cl <- nnetar(y = data_nn_cl[1:278,1], 
                    p = 12, 
                    size = 6,
                    repeats = 400,
                    xreg = data_nn_cl[1:278,2:7]
                    )

nn_fcast_cl <- forecast(nn_m_cl,
                  h = 12, 
                  PI = TRUE, 
                  level = c(80,95), 
                  fan = TRUE,
                  xreg = data_nn_cl[267:278,2:7],
                  npaths = 40
                  )
         
autoplot(nn_fcast_cl, ylab = "Inflation")    

nn_ferror_cl <- nn_fcast_cl$mean - dataCL$infCL[279:290]
autoplot(nn_ferror_cl)
```

Once more, I compare the forecast errors across models.

```{r nnetar comparison CL}
nn_vs_ar_cl <- abs(nn_ferror_cl) - abs(marclferror)
nn_vs_ar_cl

nn_vs_var_cl <- abs(nn_ferror_cl) - abs(mvarclferror)
nn_vs_var_cl

ggplot(as.data.frame(nn_vs_ar_cl), aes(nn_vs_ar_cl)) + geom_histogram()

ggplot(as.data.frame(nn_vs_var_cl), aes(nn_vs_var_cl)) + geom_histogram()
```

Here, the NN performes better than the VAR model. However, the benchamark predictions are more accurate than the nn'S.

# 6.5. NN for inflation in MX

```{r nnetar from forecast MX}

data_nn_mx <- as.matrix(dataMX[ , -1])

nn_m_mx <- nnetar(y = data_nn_mx[1:217,1], 
                    p = 12, 
                    size = 6,
                    repeats = 400,
                    xreg = data_nn_mx[1:217,2:7]
                    )

nn_fcast_mx <- forecast(nn_m_mx,
                  h = 12, 
                  PI = TRUE, 
                  level = c(80,95), 
                  fan = TRUE,
                  xreg = data_nn_mx[206:217,2:7],
                  npaths = 40
                  )
         
autoplot(nn_fcast_mx, ylab = "Inflation")    

nn_ferror_mx <- nn_fcast_mx$mean - dataMX$infMX[218:229]
autoplot(nn_ferror_mx)
```

Finally, I compare the errors of the NN and both other models.

```{r nnetar comparison MX}
nn_vs_ar_mx <- abs(nn_ferror_mx) - abs(marmxferror)
nn_vs_ar_mx

nn_vs_var_mx <- abs(nn_ferror_mx) - abs(mvarmxferror)
nn_vs_var_mx

ggplot(as.data.frame(nn_vs_ar_mx), aes(nn_vs_ar_mx)) + geom_histogram()

ggplot(as.data.frame(nn_vs_var_mx), aes(nn_vs_var_mx)) + geom_histogram()
```

In this case, the NN is outperformed by the AR(1) model. However, its forecast is better than that of a VAR model.

# 7. Trying to build a NN with keras again

After some research on the keras package for neural networks, I have decided to try to use it again. Specially since it has been proven by Bruce Meng (https://www.brucemeng.ca/post/auto-neural-networks-vs-manual-keras/) that its performance is far superior than the nnetar function of the forecast package when dealing with time series.

# 7.1. Keras NN for inflation in the US

```{r divide data US}
data_nn_us <- as.matrix(dataUS[ , -1])
```

We create general function to preprocess the data

```{r generator function}
generator <- function(data, lookback, delay, min_index, max_index,
                      shuffle = FALSE, batch_size = 128, step = 6) {
  if (is.null(max_index))
    max_index <- nrow(data) - delay - 1
  i <- min_index + lookback
  function() {
    if (shuffle) {
      rows <- sample(c((min_index+lookback):max_index), size = batch_size)
    } else {
      if (i + batch_size >= max_index)
        i <<- min_index + lookback
      rows <- c(i:min(i+batch_size-1, max_index))
      i <<- i + length(rows)
    }

    samples <- array(0, dim = c(length(rows),
                                lookback / step,
                                dim(data)[[-1]]))
    targets <- array(0, dim = c(length(rows)))
                      
    for (j in 1:length(rows)) {
      indices <- seq(rows[[j]] - lookback, rows[[j]]-1,
                     length.out = dim(samples)[[2]])
      samples[j,,] <- data[indices,]
      targets[[j]] <- data[rows[[j]] + delay,2]
    }           
    list(samples, targets)
  }
}
```

Where data is the original normalized dataset, lookback is how many periods back the input data should go, delay is the forecasting target, min_index and max_index delimit the length of the array to draw data from, shuffle indicates whether to shuffle samples or draw them in a choronological order, batch_size is the number of observations per batch and step is the period at which you sample your data.

To apply the data we specify the parameters of the generator function:

```{r generator function parameters US}
data_nn_us <- as.matrix(dataUS[ , -1])

lookback <- 12
step <- 1
delay <- 12
batch_size <- 50

train_data_us <- generator(
  data_nn_us, 
  lookback = lookback,
  delay = delay,
  min_index = 1,
  max_index = 228,
  shuffle = FALSE,
  step = step,
  batch_size = batch_size
)

val_data_us <- generator(
  data_nn_us, 
  lookback = lookback,
  delay = delay,
  min_index = 229,
  max_index = 289,
  step = step,
  batch_size = batch_size
)

test_data_us <- generator(
  data_nn_us, 
  lookback = lookback,
  delay = delay,
  min_index = 290,
  max_index = NULL,
  step = step,
  batch_size = batch_size
)

#Ammount of steps to draw from val.
val_steps <- (289 - 229 - lookback) / batch_size

#Ammount of steps to draw from test
test_steps <- (nrow(data_nn_us) - 289 - lookback) / batch_size
```

```{r keras NN US}
units_us <- 24
inputs <- 7

nn_keras_us <- keras_model_sequential()

nn_keras_us %>% 
  layer_dense(units = units_us,
              input_shape = c(lookback, inputs),
              batch_size = inputs,
              activation = "tanh") %>% 
  layer_dense(units = units_us/2,
              activation = "tanh") %>% 
  layer_dense(units = units_us/8,
              activation = "tanh") %>% 
  layer_dense(units = 1)
        
nn_keras_us %>% compile(optimizer = "rmsprop",
                        loss = "mean_squared_error",
                        metrics = "accuracy")              

nn_keras_history_us <- nn_keras_us %>% fit_generator(
  train_data_us,
  steps_per_epoch = 100,
  epochs = 40,
  validation_data = val_data_us,
  validation_steps = 1
)

plot(nn_keras_history_us)

```

The previous chnk is not working. Anyway lts prepare the code so I can forecast once the problem is solved. I will denote the amount of predictions to make as "n".

```{r keras NN forecas US}
n <- 12 


fcast_keras_us <- numeric()

for(i in 1:n){
  pred_y <- x[(nrow(x) - inputs + 1):nrow(x), 1:lookback]
  dim(pred_y) <- c(inputs, lookback)
  
  fcast_y <- nn_keras_us %>%  predict(pred_y, batch_size = inputs)
  fcast_y <- as_tibble(fcast_y)
  names(fcast_y) <- "x"
  
  data_nn_us <- rbind(data_nn_us, fcast_y)
  
  data_nn_new_us <- nnfor::lagmatrix(data_nn_us$x, 0:lookback)
  colnames(data_nn_new_us) <- paste0("x-", 0:lookback)
  data_nn_new_us <- as_tibble(data_nn_new_us) %>% 
    filter(!is.na(.[ , ncol(.)])) %>% 
    as.matrix()
  
  x <- data_nn_new_us[ , 2:(lookback + 1)]
  dim(x) <- c(nrow(x), ncol(x))
  
  y <- data_nn_new_us[ , 1]
  dim(y) <- length(y)
  
  fcast_y <- fcast_y * (max_index - min_index) + min_index
  
  fcast_keras_us[i] <- fcast_y %>% 
    InvBoxCox(1)
  fcast_keras_us <- unlist(fcast_keras_us)
  
}
```








